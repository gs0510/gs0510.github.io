---
layout: page
title: About me!
permalink: /about/
---

## Education

##BITS Pilani, Pilani Campus
B.E.(Hons.) Computer Science (2013 - 2017)

## Work Experience

#Bloomberg LP  
October 2017 - present

*   Currently working with the Allocation and Investment management team that works on the lifecycle of a trade.
*   Rearchitecting legacy system with microservices using C++ and Python.
*   Helping in adoption of golang inside Bloomberg by contributing to development efforts for Bloomberg's clustered RDBMS.

#Uber  
July 2017 - September 2017

*   Worked with the Global Vehicle Solutions team. Worked on scaling the backend for Autohawk(Vehicle Management Platform). Added features to the frontend for Autocare(Vehicle Repairs Platform).

#Linux Kernel Foundation  
May 2017 - July 2017

*   Replaced bitmap implementation for Process IDs with IDR API. The blog posts can be found [here](https://medium.com/@gargi_sharma). The commits can be seen [here.](https://github.com/torvalds/linux/commits?author=gs0510&since=2017-11-01T00:00:00Z&until=2017-11-22T00:00:00Z)

#Google CodeU  
March 2016 - August 2016

*   CodeU is a five-month development program for high potential university students to strengthen their skills and prepare them to become successful candidates for future technical opportunities.
*   Built and presented a wikipedia search engine that had features like multi-threaded web crawler, text suggestion using Lucene, TF/IDF-based heuristics to rank relevant Wiki pages.
*   Went though a comprehensive technical bootcamp under the guidance of a Google software engineer

#eBay Inc.  
May 2016 - July 2016

*   Worked with the platforms team to build a DevOps dashboard. Used Javascript, HTML, CSS to build a Node.js web application.
*   Also worked on a Trends widget that scraped fashion trends from popular websites like Vogue, Elle, etc. and searched for the corresponding listings on the website.

#Quant One Technologies(formerly Hedge Capital Quants Advisory, LLC)  
May 2015 - July 2015

*   Made a trading strategy that involved identifying Japanese Candlestick patterns for entry into markets, used Average True Range based filters for squaring off positions.
*   Also performed sentiment analysis of twitter feeds to find out the correlation between the stock market direction and the sentiment of the twitter feed.

## Research Experience

#Web Intelligence and Social Computing(WiSoc) Lab  

*   Currently working on a Deep Learning Algorithm for text summarization. Previously worked on an algorithm that uses weighted minimum vertex cover to score sentences to generate summary.
*   Also used Wikipedia based topic identification to remove dummy features and implemented algorithms to reduce redundancy in extractive text summarization.
*   Also modeled the text as a graph and used graph based algorithms to generate abstractive summaries.

## Teaching Experience

#Computer Networks CS F303  
First Degree teaching Assistant

*   Partly responsible for creating weekly lab sheets that reflect the material taught in the class that week.
*   Assisted lab sessions.

#Parallel Computing CS F422  
First Degree Teaching Assistant

*   Assisted with evaluations of assignments.
*   Conducted tutorials on pthreads and OpenMP.

## Publications

[ATSSI: Abstractive Text Summarization Using Sentiment Infusion](http://www.sciencedirect.com/science/article/pii/S187705091631153X)  
In this paper, we proposed a graph based technique that generates summaries of redundant opinions and uses sentiment analysis to combine the statements. The summaries thus generated were abstraction based summaries and were well formed to convey the gist of the text.

[Deep Paraphrase Detection in Indian Languages](https://dl.acm.org/citation.cfm?id=3122119)  
This paper presents an approach to the problem of paraphrase identification in English and Indian languages using Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN). The lack of NLP resources for Indian languages has been a deterrent to the advancement of paraphrase detection task in Indian languages. Three approaches have been proposed, a simple CNN that uses word embeddings as input, a CNN that uses WordNet scores as input and RNN based approach with both LSTM and bi-directional LSTM.

